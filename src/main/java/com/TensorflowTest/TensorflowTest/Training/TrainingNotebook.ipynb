{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SEPAL_LENGTH = 'SepalLength'\n",
    "FEATURE_SEPAL_WIDTH = 'SepalWidth'\n",
    "FEATURE_PETAL_LENGTH = 'PetalLength'\n",
    "FEATURE_PETAL_WIDTH = 'PetalWidth'\n",
    "LABEL = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_data_w_target = [];\n",
    "\n",
    "# add the target to the data\n",
    "for i in range(len(iris.data)):\n",
    "    value = np.append(iris.data[i], iris.target[i])\n",
    "    iris_data_w_target.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = [FEATURE_SEPAL_LENGTH, FEATURE_SEPAL_WIDTH, FEATURE_PETAL_LENGTH, FEATURE_PETAL_WIDTH, LABEL]\n",
    "\n",
    "df = pd.DataFrame(data = iris_data_w_target, columns = columns_names )\n",
    "\n",
    "# shuffle our data\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into training and testing data (80%/20%)\n",
    "test_len = (len(df) * 20)//100;\n",
    "training_df = df[test_len:]\n",
    "test_df = df[:test_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_feature_columns = [\n",
    "    tf.contrib.layers.real_valued_column(FEATURE_SEPAL_LENGTH, dimension=1, dtype=tf.float32),\n",
    "    tf.contrib.layers.real_valued_column(FEATURE_SEPAL_WIDTH, dimension=1, dtype=tf.float32),\n",
    "    tf.contrib.layers.real_valued_column(FEATURE_PETAL_LENGTH, dimension=1, dtype=tf.float32),\n",
    "    tf.contrib.layers.real_valued_column(FEATURE_PETAL_WIDTH, dimension=1, dtype=tf.float32)\n",
    "]\n",
    "\n",
    "x = {\n",
    "    FEATURE_SEPAL_LENGTH : np.array(training_df[FEATURE_SEPAL_LENGTH]),\n",
    "    FEATURE_SEPAL_WIDTH  : np.array(training_df[FEATURE_SEPAL_WIDTH]),\n",
    "    FEATURE_PETAL_LENGTH : np.array(training_df[FEATURE_PETAL_LENGTH]),\n",
    "    FEATURE_PETAL_WIDTH  : np.array(training_df[FEATURE_PETAL_WIDTH])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'models/iris', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000029787781C88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into models/iris\\model.ckpt.\n",
      "INFO:tensorflow:loss = 180.04369, step = 1\n",
      "INFO:tensorflow:global_step/sec: 366.972\n",
      "INFO:tensorflow:loss = 50.650856, step = 101 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.056\n",
      "INFO:tensorflow:loss = 40.605988, step = 201 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.385\n",
      "INFO:tensorflow:loss = 31.324093, step = 301 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.506\n",
      "INFO:tensorflow:loss = 25.247364, step = 401 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 445.439\n",
      "INFO:tensorflow:loss = 16.20399, step = 501 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.706\n",
      "INFO:tensorflow:loss = 17.183968, step = 601 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.144\n",
      "INFO:tensorflow:loss = 13.499233, step = 701 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.325\n",
      "INFO:tensorflow:loss = 10.442471, step = 801 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.781\n",
      "INFO:tensorflow:loss = 8.936228, step = 901 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.47\n",
      "INFO:tensorflow:loss = 9.401176, step = 1001 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.842\n",
      "INFO:tensorflow:loss = 8.361078, step = 1101 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.008\n",
      "INFO:tensorflow:loss = 8.888293, step = 1201 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.908\n",
      "INFO:tensorflow:loss = 9.568013, step = 1301 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.827\n",
      "INFO:tensorflow:loss = 5.5224056, step = 1401 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.717\n",
      "INFO:tensorflow:loss = 5.15819, step = 1501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.204\n",
      "INFO:tensorflow:loss = 8.591214, step = 1601 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.516\n",
      "INFO:tensorflow:loss = 7.0566635, step = 1701 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.622\n",
      "INFO:tensorflow:loss = 7.515561, step = 1801 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.911\n",
      "INFO:tensorflow:loss = 7.105917, step = 1901 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.489\n",
      "INFO:tensorflow:loss = 3.8934705, step = 2001 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 506.329\n",
      "INFO:tensorflow:loss = 4.225885, step = 2101 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.059\n",
      "INFO:tensorflow:loss = 6.680647, step = 2201 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.515\n",
      "INFO:tensorflow:loss = 2.5332391, step = 2301 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.702\n",
      "INFO:tensorflow:loss = 3.6942754, step = 2401 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.587\n",
      "INFO:tensorflow:loss = 6.720794, step = 2501 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.518\n",
      "INFO:tensorflow:loss = 5.585128, step = 2601 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.758\n",
      "INFO:tensorflow:loss = 2.0980747, step = 2701 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.464\n",
      "INFO:tensorflow:loss = 7.3420386, step = 2801 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.67\n",
      "INFO:tensorflow:loss = 5.130738, step = 2901 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.256\n",
      "INFO:tensorflow:loss = 5.8189735, step = 3001 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.994\n",
      "INFO:tensorflow:loss = 4.3887863, step = 3101 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.808\n",
      "INFO:tensorflow:loss = 6.3383145, step = 3201 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.355\n",
      "INFO:tensorflow:loss = 1.8972809, step = 3301 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.788\n",
      "INFO:tensorflow:loss = 4.1478443, step = 3401 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.048\n",
      "INFO:tensorflow:loss = 5.092847, step = 3501 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.258\n",
      "INFO:tensorflow:loss = 5.1466055, step = 3601 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.387\n",
      "INFO:tensorflow:loss = 4.1918545, step = 3701 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.431\n",
      "INFO:tensorflow:loss = 4.5978103, step = 3801 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.201\n",
      "INFO:tensorflow:loss = 1.7713236, step = 3901 (0.205 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into models/iris\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.8899975.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x29787781eb8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns = iris_feature_columns,\n",
    "        hidden_units = [5, 5],\n",
    "        model_dir = 'models/iris',\n",
    "        n_classes = 3)\n",
    "\n",
    "\n",
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = x,\n",
    "    y = np.array(training_df[LABEL]).astype(int),\n",
    "    num_epochs = None,\n",
    "    shuffle = True)\n",
    "\n",
    "# Train model.\n",
    "classifier.train(input_fn = train_input_fn, steps = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-02-10:51:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-02-10:51:22\n",
      "INFO:tensorflow:Saving dict for global step 4000: accuracy = 0.96666664, average_loss = 0.10721865, global_step = 4000, loss = 3.2165596\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: models/iris\\model.ckpt-4000\n",
      "Test Accuracy:  0.96666664\n"
     ]
    }
   ],
   "source": [
    "x = {\n",
    "    FEATURE_SEPAL_LENGTH : np.array(test_df[FEATURE_SEPAL_LENGTH]),\n",
    "    FEATURE_SEPAL_WIDTH  : np.array(test_df[FEATURE_SEPAL_WIDTH]),\n",
    "    FEATURE_PETAL_LENGTH : np.array(test_df[FEATURE_PETAL_LENGTH]),\n",
    "    FEATURE_PETAL_WIDTH  : np.array(test_df[FEATURE_PETAL_WIDTH])\n",
    "}\n",
    "\n",
    "# Define the training inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = x,\n",
    "    y = np.array(test_df[LABEL]).astype(int),\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "print(\"Test Accuracy: \", accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from models/iris\\model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"0\" (certainity 100.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (certainity 100.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"2\" (certainity 100.0%), expected \"2\"\n"
     ]
    }
   ],
   "source": [
    "x = {\n",
    "    FEATURE_SEPAL_LENGTH : np.array([5.0, 6.7, 7.4]),\n",
    "    FEATURE_SEPAL_WIDTH  : np.array([3.5, 3.1, 2.8]),\n",
    "    FEATURE_PETAL_LENGTH : np.array([1.3, 4.4, 6.1]),\n",
    "    FEATURE_PETAL_WIDTH  : np.array([0.3, 1.4, 1.9])\n",
    "}\n",
    "\n",
    "expected = np.array([0, 1, 2])\n",
    "\n",
    "# Define the training inputs\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = x,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "\n",
    "predictions = classifier.predict(input_fn = predict_input_fn)\n",
    "\n",
    "for pred_dict, expec in zip(predictions, expected):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('\\nPrediction is \"{}\" (certainity {:.1f}%), expected \"{}\"'.format(class_id, 100 * probability, expec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "DecodeError",
     "evalue": "Error parsing message",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-edb81d34fccf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stored_model/1533207083/saved_model.pb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgraph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     onnx_model = tensorflow_graph_to_onnx_model(graph_def,\n\u001b[0;32m     12\u001b[0m                                      \u001b[1;34m\"outputs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#This is the output node\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDecodeError\u001b[0m: Error parsing message"
     ]
    }
   ],
   "source": [
    "#Generates a graph proto for use in conversion later\n",
    "\n",
    "with open(\"models/iris/graph.proto\", \"wb\") as file:\n",
    "  graph = tf.get_default_graph().as_graph_def(add_shapes=True)\n",
    "  file.write(graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from models/iris\\model.ckpt-4000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: stored_model\\temp-b'1533207083'\\saved_model.pb\n",
      "Model binary exported to stored_model\\1533207083\n"
     ]
    }
   ],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    serialized_tf_example = tf.placeholder(dtype = tf.string, shape = [None], name = 'input_tensors')\n",
    "    receiver_tensors      = {'predictor_inputs' : serialized_tf_example}\n",
    "    feature_spec          = {FEATURE_SEPAL_LENGTH : tf.FixedLenFeature([25], tf.float32),\n",
    "                             FEATURE_SEPAL_WIDTH  : tf.FixedLenFeature([25], tf.float32),\n",
    "                             FEATURE_PETAL_LENGTH : tf.FixedLenFeature([25], tf.float32),\n",
    "                             FEATURE_PETAL_WIDTH  : tf.FixedLenFeature([25], tf.float32)}\n",
    "    features              = tf.parse_example(serialized_tf_example, feature_spec)\n",
    "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
    "\n",
    "\n",
    "# Saves model as text\n",
    "#model_dir = classifier.export_savedmodel(export_dir_base = \"stored_model\", \n",
    "#                             serving_input_receiver_fn = serving_input_receiver_fn,\n",
    "#                             as_text = True)\n",
    "#print('Model exported to '+ model_dir.decode())\n",
    "\n",
    "# Saves model as not-text\n",
    "model_dir = classifier.export_savedmodel(export_dir_base = \"stored_model\", \n",
    "                             serving_input_receiver_fn = serving_input_receiver_fn,\n",
    "                             as_text = False)\n",
    "print('Model binary exported to '+ model_dir.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
