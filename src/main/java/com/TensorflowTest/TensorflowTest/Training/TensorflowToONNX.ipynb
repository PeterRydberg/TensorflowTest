{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from onnx_tf.frontend import tensorflow_graph_to_onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proto and graph freezing defined from\n",
    "# https://github.com/onnx/tutorials/blob/master/tutorials/OnnxTensorflowExport.ipynb\n",
    "\n",
    "# Bazel command below should find output node:\n",
    "# bazel build C:\\Users\\camp-pry\\AppData\\Local\\Continuum\\anaconda3\\envs\\tensorflow_iris\\Lib\\site-packages\\tensorflow\\tools\\graph_transforms:summarize_graph\n",
    "#    bazel-bin/tensorflow/tools/graph_transforms/summarize_graph \n",
    "#    --in_graph=C:\\Users\\camp-pry\\IdeaProjects\\TensorflowTest\\src\\main\\java\\com\\TensorflowTest\\TensorflowTest\\Training\\stored_model\\1533207083\\saved_model.pb\n",
    "\n",
    "# Bazel command below should generate new frozen model:\n",
    "#bazel build tensorflow/python/tools:freeze_graph\n",
    "#bazel-bin/tensorflow/python/tools/freeze_graph \\\n",
    "#    --input_graph=/home/mnist-tf/graph.proto \\\n",
    "#    --input_checkpoint=/home/mnist-tf/ckpt/model.ckpt \\\n",
    "#    --output_graph=/tmp/frozen_graph.pb \\\n",
    "#    --output_node_names=fc2/add \\\n",
    "#    --input_binary=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Exposes the Python wrapper for graph transforms.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# pylint: disable=unused-import,wildcard-import, line-too-long\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.pywrap_tensorflow import TransformGraphWithStringInputs\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "\n",
    "def TransformGraph(input_graph_def, inputs, outputs, transforms):\n",
    "  \"\"\"Python wrapper for the Graph Transform Tool.\n",
    "\n",
    "  Gives access to all graph transforms available through the command line tool.\n",
    "  See documentation at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md\n",
    "  for full details of the options available.\n",
    "\n",
    "  Args:\n",
    "    input_graph_def: GraphDef object containing a model to be transformed.\n",
    "    inputs: List of node names for the model inputs.\n",
    "    outputs: List of node names for the model outputs.\n",
    "    transforms: List of strings containing transform names and parameters.\n",
    "\n",
    "  Returns:\n",
    "    New GraphDef with transforms applied.\n",
    "  \"\"\"\n",
    "\n",
    "  input_graph_def_string = input_graph_def.SerializeToString()\n",
    "  inputs_string = compat.as_bytes(\",\".join(inputs))\n",
    "  outputs_string = compat.as_bytes(\",\".join(outputs))\n",
    "  transforms_string = compat.as_bytes(\" \".join(transforms))\n",
    "  with errors.raise_exception_on_not_ok_status() as status:\n",
    "    output_graph_def_string = TransformGraphWithStringInputs(\n",
    "        input_graph_def_string, inputs_string, outputs_string,\n",
    "        transforms_string, status)\n",
    "  output_graph_def = graph_pb2.GraphDef()\n",
    "  output_graph_def.ParseFromString(output_graph_def_string)\n",
    "  return output_graph_def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "DecodeError",
     "evalue": "Error parsing message",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDecodeError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-170c1adb2d83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stored_model/1533207083/saved_model.pb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgraph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgraph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     onnx_model = tensorflow_graph_to_onnx_model(graph_def,\n\u001b[0;32m      6\u001b[0m                                      \u001b[1;34m\"outputs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#This is the output node\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDecodeError\u001b[0m: Error parsing message"
     ]
    }
   ],
   "source": [
    "# Converts frozen model to ONNX format\n",
    "with tf.gfile.GFile(\"stored_model/1533207083/saved_model.pb\", \"rb\") as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    onnx_model = tensorflow_graph_to_onnx_model(graph_def,\n",
    "                                     \"outputs\", #This is the output node\n",
    "                                     opset=6)\n",
    "\n",
    "    file = open(\"models/iris/graph.onnx\", \"wb\")\n",
    "    file.write(onnx_model.SerializeToString())\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
