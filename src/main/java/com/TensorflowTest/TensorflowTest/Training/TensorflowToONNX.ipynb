{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from onnx_tf.frontend import tensorflow_graph_to_onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models\\iris\\model.ckpt-4000\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "INFO:tensorflow:Converted 6 variables to const ops.\n",
      "78 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "import os, argparse\n",
    "\n",
    "# The original freeze_graph function\n",
    "# from tensorflow.python.tools.freeze_graph import freeze_graph \n",
    "\n",
    "#dir = os.path.dirname(os.path.realpath(__file__))\n",
    "\n",
    "def freeze_graph(model_dir, output_node_names):\n",
    "    \"\"\"Extract the sub graph defined by the output nodes and convert \n",
    "    all its variables into constant \n",
    "    Args:\n",
    "        model_dir: the root folder containing the checkpoint state file\n",
    "        output_node_names: a string, containing all the output node's names, \n",
    "                            comma separated\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exist. Please specify an export \"\n",
    "            \"directory: %s\" % model_dir)\n",
    "\n",
    "    if not output_node_names:\n",
    "        print(\"You need to supply the name of a node to --output_node_names.\")\n",
    "        return -1\n",
    "    \n",
    "    # Prints all nodes in graph for debugging\n",
    "    #[print(n.name) for n in tf.get_default_graph().as_graph_def().node]\n",
    "\n",
    "    # We retrieve our checkpoint fullpath\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "    \n",
    "    # We precise the file fullname of our freezed graph\n",
    "    absolute_model_dir = \"/\".join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + \"/frozen_model.pb\"\n",
    "\n",
    "    # We clear devices to allow TensorFlow to control on which device it will load operations\n",
    "    clear_devices = True\n",
    "\n",
    "    # We start a session using a temporary fresh Graph\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        # We import the meta graph in the current default Graph\n",
    "        saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "\n",
    "        # We restore the weights\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "\n",
    "        # We use a built-in TF helper to export variables to constants\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess, # The session is used to retrieve the weights\n",
    "            tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "            output_node_names.split(\",\") # The output node names are used to select the useful nodes\n",
    "        ) \n",
    "\n",
    "        # Finally we serialize and dump the output graph to the filesystem\n",
    "        with tf.gfile.GFile('models/iris/' + output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
    "\n",
    "    #return output_graph_def\n",
    "\n",
    "freeze_graph(\"models\\iris\", \"dnn/head/predictions/class_ids,dnn/head/predictions/probabilities\") # Runs freezer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\camp-pry\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_iris\\lib\\site-packages\\onnx_tf\\frontend.py:533: UserWarning: RandomShuffleQueueV2 op is not implemented.\n",
      "  exception(message)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You passed in an iterable attribute but I cannot figure out its applicable type.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-9f6d27b039e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                                      \u001b[1;31m#opset=6,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                      \u001b[0mgraph_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"graph\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                                      ignore_unimplemented=True)\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"models/iris/graph.onnx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camp-pry\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_iris\\lib\\site-packages\\onnx_tf\\frontend.py\u001b[0m in \u001b[0;36mtensorflow_graph_to_onnx_model\u001b[1;34m(cls, graph_def, output, opset, producer_name, graph_name, ignore_unimplemented)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     onnx_graph = cls.tensorflow_graph_to_onnx_graph(\n\u001b[1;32m--> 442\u001b[1;33m         graph_def, output_node, opset, graph_name, ignore_unimplemented)\n\u001b[0m\u001b[0;32m    443\u001b[0m     onnx_model = make_model(\n\u001b[0;32m    444\u001b[0m         onnx_graph, producer_name=producer_name, opset_imports=opset_imports)\n",
      "\u001b[1;32mc:\\users\\camp-pry\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_iris\\lib\\site-packages\\onnx_tf\\frontend.py\u001b[0m in \u001b[0;36mtensorflow_graph_to_onnx_graph\u001b[1;34m(cls, graph_def, output, opset, name, ignore_unimplemented)\u001b[0m\n\u001b[0;32m    300\u001b[0m                   \u001b[0mconsts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconsts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m                   \u001b[0mnode_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_tup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                   onnx_op=onnx_op))\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorflowNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camp-pry\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_iris\\lib\\site-packages\\onnx_tf\\frontend.py\u001b[0m in \u001b[0;36mhandle_trivial\u001b[1;34m(cls, node, **kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m                node.attr.items()))\n\u001b[0;32m    460\u001b[0m     \u001b[0mattr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmake_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monnx_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camp-pry\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_iris\\lib\\site-packages\\onnx\\helper.py\u001b[0m in \u001b[0;36mmake_node\u001b[1;34m(op_type, inputs, outputs, name, doc_string, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m         node.attribute.extend(\n\u001b[0;32m     50\u001b[0m             \u001b[0mmake_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             for key, value in sorted(kwargs.items()))\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camp-pry\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_iris\\lib\\site-packages\\onnx\\helper.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         node.attribute.extend(\n\u001b[0;32m     50\u001b[0m             \u001b[0mmake_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             for key, value in sorted(kwargs.items()))\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\camp-pry\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_iris\\lib\\site-packages\\onnx\\helper.py\u001b[0m in \u001b[0;36mmake_attribute\u001b[1;34m(key, value, doc_string)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             raise ValueError(\n\u001b[1;32m--> 230\u001b[1;33m                 \u001b[1;34m\"You passed in an iterable attribute but I cannot figure out \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m                 \"its applicable type.\")\n\u001b[0;32m    232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You passed in an iterable attribute but I cannot figure out its applicable type."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Converts frozen model to ONNX format\n",
    "with tf.gfile.GFile(\"models/iris/frozen_model.pb\", \"rb\") as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    onnx_model = tensorflow_graph_to_onnx_model(graph_def,\n",
    "                                     \"dnn/head/predictions/class_ids\", #This is the output node\n",
    "                                     #opset=6,\n",
    "                                     graph_name=\"graph\",\n",
    "                                     ignore_unimplemented=True)\n",
    "\n",
    "    file = open(\"models/iris/graph.onnx\", \"wb\")\n",
    "    file.write(onnx_model.SerializeToString())\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
